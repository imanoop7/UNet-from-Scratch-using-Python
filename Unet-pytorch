import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
from scipy.ndimage import gaussian_filter

class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels, n_classes):
        super(UNet, self).__init__()
        
        # Encoder (downsampling)
        self.encoder1 = DoubleConv(n_channels, 64)
        self.encoder2 = DoubleConv(64, 128)
        self.encoder3 = DoubleConv(128, 256)
        self.encoder4 = DoubleConv(256, 512)

        self.pool = nn.MaxPool2d(2)
        
        # Middle (bottleneck)
        self.middle = DoubleConv(512, 1024)
        
        # Decoder (upsampling)
        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)
        self.decoder4 = DoubleConv(1024, 512)
        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.decoder3 = DoubleConv(512, 256)
        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.decoder2 = DoubleConv(256, 128)
        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.decoder1 = DoubleConv(128, 64)

        self.final_conv = nn.Conv2d(64, n_classes, 1)

    def forward(self, x):
        # Encoder
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(self.pool(enc1))
        enc3 = self.encoder3(self.pool(enc2))
        enc4 = self.encoder4(self.pool(enc3))

        # Middle
        middle = self.middle(self.pool(enc4))

        # Decoder
        dec4 = self.upconv4(middle)
        dec4 = torch.cat([dec4, self.crop(enc4, dec4)], dim=1)
        dec4 = self.decoder4(dec4)

        dec3 = self.upconv3(dec4)
        dec3 = torch.cat([dec3, self.crop(enc3, dec3)], dim=1)
        dec3 = self.decoder3(dec3)

        dec2 = self.upconv2(dec3)
        dec2 = torch.cat([dec2, self.crop(enc2, dec2)], dim=1)
        dec2 = self.decoder2(dec2)

        dec1 = self.upconv1(dec2)
        dec1 = torch.cat([dec1, self.crop(enc1, dec1)], dim=1)
        dec1 = self.decoder1(dec1)

        # Add padding to match input dimensions
        diff_h = x.size()[2] - dec1.size()[2]
        diff_w = x.size()[3] - dec1.size()[3]
        dec1 = nn.functional.pad(dec1, [diff_w // 2, diff_w - diff_w // 2, diff_h // 2, diff_h - diff_h // 2])

        return self.final_conv(dec1)

    def crop(self, enc_feature, dec_feature):
        """
        Center crop enc_feature to match dec_feature's dimensions
        """
        _, _, H, W = dec_feature.shape
        return enc_feature[:, :, :H, :W]

def create_cell(image, center, radius, intensity):
    y, x = np.ogrid[:image.shape[0], :image.shape[1]]
    dist_from_center = np.sqrt((x - center[0])**2 + (y - center[1])**2)
    mask = dist_from_center <= radius
    image[mask] = np.maximum(image[mask], intensity * (1 - dist_from_center[mask] / radius))

def create_multicell_image(size=572, num_cells=10):
    image = np.zeros((size, size), dtype=np.float32)
    mask = np.zeros((size, size), dtype=np.float32)
    
    for _ in range(num_cells):
        center = (np.random.randint(0, size), np.random.randint(0, size))
        radius = np.random.randint(20, 60)
        intensity = np.random.uniform(0.5, 1.0)
        
        create_cell(image, center, radius, intensity)
        create_cell(mask, center, radius, 1.0)
    
    # Add background noise
    noise = np.random.normal(0, 0.1, (size, size))
    image += noise
    
    # Apply Gaussian blur
    image = gaussian_filter(image, sigma=1)
    
    # Clip values to [0, 1] range
    image = np.clip(image, 0, 1)
    
    return image, mask

def test_unet():
    # Create a synthetic multicell image
    cell_image, true_mask = create_multicell_image(572)
    
    # Convert to PyTorch tensor and add batch and channel dimensions
    x = torch.from_numpy(cell_image).unsqueeze(0).unsqueeze(0)
    
    model = UNet(n_channels=1, n_classes=2)
    
    # Set model to evaluation mode and disable gradient computation
    model.eval()
    with torch.no_grad():
        preds = model(x)
    
    print(f"Input shape: {x.shape}")
    print(f"Output shape: {preds.shape}")
    assert preds.shape == (1, 2, 572, 572), f"Expected shape (1, 2, 572, 572), but got {preds.shape}"
    print("UNet test passed!")

    # Apply softmax to get probabilities
    preds_probs = torch.softmax(preds, dim=1)

    # Visualize input, true mask, and output
    plt.figure(figsize=(20, 5))

    # Plot the input image
    plt.subplot(1, 4, 1)
    plt.imshow(cell_image, cmap='gray')
    plt.title('Input Image')
    plt.axis('off')

    # Plot the true mask
    plt.subplot(1, 4, 2)
    plt.imshow(true_mask, cmap='gray')
    plt.title('True Mask')
    plt.axis('off')

    # Plot the output (background probability)
    plt.subplot(1, 4, 3)
    plt.imshow(preds_probs[0, 0].numpy(), cmap='viridis')
    plt.title('Predicted Background Probability')
    plt.axis('off')

    # Plot the output (cell probability)
    plt.subplot(1, 4, 4)
    plt.imshow(preds_probs[0, 1].numpy(), cmap='viridis')
    plt.title('Predicted Cell Probability')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    test_unet()